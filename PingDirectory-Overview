Introduction to the PingDirectory server
The PingDirectory server is a high-performance, extensible Lightweight Directory Access Protocol (LDAP) directory that provides seamless data management over a distributed system while meeting the constant performance demands for today‚Äôs markets.
The PingDirectory server centralizes consumer and user identity management information, subscriber data management, application configurations, and user credentials into a network, enterprise, or virtualized database environment.

------------------------------------------------------------------------------------------------------------

Features of PingDirectory Server:
High performance data store for both read and writes. 
¬ßExtensible directory written completely in Java. 
¬ß Uses N-way multi-master replication, which supports data sharding and sovereignty requirements.
¬ß Next generation with support for high-level encryption strategies, JSON, and REST APIs.
-----------------------------------------------------------------------------

What is this muti-master replication?

"N-way Multi-Master Replication" in PingDirectory
In N-way multi-master replication, every server is a master.That means any server in the replication topology can accept read and write operations.
All write changes are replicated to the other servers automatically.This is exactly how PingDirectory's replication works by default ‚Äî there‚Äôs no "primary" or "secondary" like in traditional systems.
In short:
All your PD servers are equals ("masters").
Any server can serve users and write data, and PingDirectory syncs those writes to others.
------------------------------------------------------------------------------------------------

What is data sharding?

"Supports Data Sharding and Sovereignty Requirements" ‚Äî what this means in PD
Data Sharding:
Normally, all PD servers hold the same full dataset (full replication).But you can shard data if needed ‚Äî for example:Server 1 holds users starting with A‚ÄìM.Server 2 holds users starting with N‚ÄìZ.This is called Sub-Tree Replication or using different baseDNs.
You control which part of the DIT (directory tree) is replicated.

--------------------------------------------------------------------------------------------------------------------------------------

Data Sovereignty:
Some countries/laws (like GDPR) require data to stay within borders (EU data stays in EU).In PingDirectory, you can configure WAN Gateway replication and Location-based replication priorities.That way, data updates across countries happen in a controlled way.Example: Only certain servers sync across WAN (slow link) to comply with legal policies.

-------------------------------------------------------------------------------------------------------------------------------------------

Backend Database for PD:

Backend Database
Uses Oracle Berkeley DB Java Edition (JE): ‚Äì Highly performant for read/writes. ‚Äì 
Supports ACID transactions:
üî∏ Atomicity
All changes in a transaction happen as one unit ‚Äî either all succeed or none happen.
Example:
If you add a user and update their group in one transaction, both operations must succeed together. If one fails, everything rolls back.
üî∏ Consistency
The database is always in a valid state ‚Äî no partial or corrupt changes are left behind.
Example:
If your schema requires a user to have a userID and email, the DB ensures you can‚Äôt end up with only one of them saved.
üî∏ Isolation
While a transaction is running, its changes are invisible to others until committed.
Example:
If two admins are updating the same user, they won‚Äôt see each other‚Äôs changes until the transaction finishes. This prevents conflicts.
üî∏ Durability
Once a transaction is committed, its changes are permanently stored, even if the system crashes.
Example:
If you commit a new record and then your app crashes, the record is still there when you restart.

------------------------------------------------------------------------------------------------------------------------------------------------

How does the Oracle Berkley JE works?

"JE uses a log-structured filesystem..."JE = Java Edition Berkeley DB (the embedded database PingDirectory uses under the hood).It doesn't use big, single, heavy database files like traditional RDBMS systems (e.g., Oracle or MySQL).Instead, everything is written as a sequence of logs ‚Äî just like a diary.Each operation (add, modify, delete) is appended to a log file sequentially.So data is always written at the end ‚Äî no jumping around to different file locations.

‚úÖ Result:
Faster writes, no fragmentation, and easier crash recovery.

2. "Eliminates the need to tune page sizes..."
Traditional databases (like RDBMS) store data in fixed-size pages (say 4KB, 8KB).You have to "tune" the page size based on the data type, usage, workload etc.JE doesn't need that.
Because everything is written sequentially into logs, there's no concept of "page tuning."

‚úÖ Result:
Simpler management ‚Äî less DB tuning, better out-of-the-box performance.

3. "JE only performs sequential writes and runs automatic cleaning..."
Since it's sequential writing only, old data builds up over time (like in a diary ‚Äî you have old entries you don't need anymore).Automatic Cleaning,JE has a background "cleaner" that.Finds obsolete or overwritten records,Compacts the data,Frees up disk space.

‚úÖ Result:
Database stays compact and healthy without you needing to manually intervene

A Berkeley DB JE environment can be composed of multiple databases, each of which is stored in a single folder on the file system. Rather than having separate files for records and transaction logs, Berkeley DB JE uses a rolling log file to store everything; this includes the B-Tree structure, the user provided records and the indexes.  Write operations append entries as the last items in the log file.  When a certain size is reached (10MB by default), a new log file is created.  This results in consistent write performance regardless of the database size.

The Berkeley DB Java Edition has a number of threads that periodically check the occupancy of each log. If it detects that the size associated with active entries falls below a certain threshold (50% of its maximum size, or 5MB by default), it rewrites the active records to the end of the latest log file and deletes the old log altogether. This can be seen in the log found at row 2, column 5.
üß† What‚Äôs Happening?
Berkeley DB stores data in log files on disk, and over time, some of this data becomes stale or obsolete (e.g., deleted keys, old versions of updated records).
To avoid wasting disk space and keep performance high, Berkeley DB uses background threads to check log file occupancy and clean them up when necessary.
1. Background Threads
There are internal threads running periodically (automatically).These threads inspect the occupancy of each log file.

2. Occupancy Check
Each log file has a certain amount of active (still-used) and inactive (obsolete) data.If the active portion drops below a threshold.By default, less than 50% full,Or less than 5 MB of active data.Then that file is considered "underutilized".

3. Cleaning Process
The cleaner rewrites active records from that log file to the end of the most recent log file.This ensures those active records are not lost when the old file is deleted.
4. Deleting the Old Log File
After all active records have been moved,The old log file (which is now mostly or completely inactive) is deleted.

üîç Where You See This (Log Example):
‚ÄúThis can be seen in the log found at row 2, column 5.‚Äù
That likely refers to a log table or admin UI (perhaps in a diagnostic or monitoring tool) showing when logs were cleaned and how many records were rewritten.

‚úÖ Benefits:
Saves disk space by removing obsolete data.
Improves performance by reducing fragmentation.
Keeps the log files lean and efficient.

--------------------------------------------------------------------
 JE Cleaning example:
 
Setup: Imagine a Log File
Let‚Äôs say you have a log file called 00000001.jdb, and it is:
10 MB in size,Contains 10,000 records originally

üìà Scenario 1: After many updates and deletes
Over time:
You update 4,000 records
 ‚Üí Old versions are no longer needed
You delete 2,000 records
 ‚Üí These are now obsolete too
So:
Only 4,000 records are still "active"
That's 4 MB of active data
 (assuming each record is ~1 KB)

üìâ Active Data Calculation:
Total size of the log = 10 MB

Active data = 4 MB

Utilization = 4 MB10 MB√ó100=40%\frac{4 \text{ MB}}{10 \text{ MB}} \times 100 = 40\%10 MB4 MB‚Äã√ó100=40%

üö® This triggers the cleaner
Since active data < 50%, the cleaner thread will:
Copy the 4,000 still-active records to the latest log file (e.g., 00000005.jdb)


Delete the old file 00000001.jdb entirely
 ‚Üí It‚Äôs no longer needed

‚úÖ End Result:
Disk space is reclaimed
Active data is consolidated at the end
System stays fast and lean









